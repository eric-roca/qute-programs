#!/usr/bin/env python3

import os
import re
import urllib.request
from urllib.parse import urljoin

FIFO_PATH = os.getenv("QUTE_FIFO")
DOWNLOAD_DIR = os.path.expanduser("~/Downloads")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36"
}


def message_fifo(message, level="warning"):
    """
    Send a message to the qutebrowser FIFO.
    
    Args:
        message (str): The message to send.
        level (str): The level of the message. Must be one of 'info',
            'warning' (default), or 'error'.
    """
    with open(FIFO_PATH, "w") as fifo:
        fifo.write(f"message-{level} '{message}'")


def find_doi(url):
    """
    Find the DOI on a web page.
    
    Args:
        url (str): The URL of the web page.
    
    Returns:
        str or None: The found DOI, or None if no DOI is found.
    """
    doi_regex = re.compile(r"10\.\d+/[\w|\.|/|-]+")
    doi = doi_regex.findall(url)
    if doi:
        return doi[0]

    try:
        req = urllib.request.Request(url, headers=HEADERS)
        url_text = urllib.request.urlopen(req).read().decode()
        doi = doi_regex.findall(url_text)
        if doi:
            message_fifo(
                f"Found {len(doi)} DOIs on page, selecting {doi[0]}", level="info"
            )
            return doi[0]
    except (urllib.error.URLError, urllib.error.HTTPError):
        message_fifo("Failed to retrieve URL")
    
    message_fifo("No DOIs found on page")
    return None


def scihub_url(doi):
    """
    Generate the Sci-Hub URL for a given DOI.
    
    Args:
        doi (str): The DOI.
    
    Returns:
        str: The Sci-Hub URL.
    """
    return urljoin("https://sci-hub.hkvisa.net/", doi)


def download_doi(scihub_url, doi):
    """
    Download the PDF corresponding to a DOI from Sci-Hub.
    
    Args:
        scihub_url (str): The Sci-Hub URL.
        doi (str): The DOI.
    
    Returns:
        str or None: The path to the downloaded PDF file, or None if the download fails.
    """
    try:
        response = urllib.request.urlopen(scihub_url).read().decode()
        pdf_links = re.findall(r"href=\'(?:https:)?//(.+\.pdf)", response)
        if pdf_links:
            pdf_location = urljoin("https://", pdf_links[0])
            doi = doi.replace("/", "_")
            download_path = os.path.join(DOWNLOAD_DIR, doi + ".pdf")
            urllib.request.urlretrieve(pdf_location, download_path)
            doi = doi.replace("_", "/")
            
            if os.path.isfile(download_path):
                message_fifo(f"DOI {doi} downloaded", level="info")
                return download_path
    except (urllib.error.URLError, urllib.error.HTTPError):
        message_fifo("Failed to download DOI")
    
    return None


url = os.getenv("QUTE_URL")
doi = find_doi(url)
if doi:
    scihub = scihub_url(doi)
    article = download_doi(scihub, doi)

    if article:
        os.system("xdg-open " + article)

